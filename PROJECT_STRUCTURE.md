# Project Structure

```
scrapper/
â”‚
â”œâ”€â”€ src/                           # Source code
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config.js              # Configuration management
â”‚   â”‚
â”‚   â”œâ”€â”€ scrapers/                  # Platform-specific scrapers
â”‚   â”‚   â”œâ”€â”€ youtube.js             # YouTube Data API v3 scraper
â”‚   â”‚   â”œâ”€â”€ instagram.js           # Instagram web scraper
â”‚   â”‚   â””â”€â”€ twitter.js             # Twitter API v2 scraper
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                     # Utility modules
â”‚   â”‚   â”œâ”€â”€ logger.js              # Winston logger
â”‚   â”‚   â”œâ”€â”€ rateLimiter.js         # Rate limiting with p-queue
â”‚   â”‚   â””â”€â”€ dataOrganizer.js       # Dataset organization & export
â”‚   â”‚
â”‚   â”œâ”€â”€ index.js                   # Main PersonaScraper class
â”‚   â””â”€â”€ cli.js                     # Command-line interface
â”‚
â”œâ”€â”€ examples/                      # Usage examples
â”‚   â”œâ”€â”€ basic_usage.js             # JavaScript examples
â”‚   â””â”€â”€ training_dataset_format.md # ML dataset documentation
â”‚
â”œâ”€â”€ data/                          # Output directory (created on first run)
â”‚   â””â”€â”€ [persona_name]/            # One folder per persona
â”‚       â”œâ”€â”€ metadata.json          # Persona overview
â”‚       â”œâ”€â”€ summary.json           # Scraping statistics
â”‚       â”œâ”€â”€ training_dataset.json  # ML-ready aggregated dataset
â”‚       â”œâ”€â”€ youtube/               # YouTube data
â”‚       â”œâ”€â”€ instagram/             # Instagram data
â”‚       â”œâ”€â”€ twitter/               # Twitter data
â”‚       â””â”€â”€ raw/                   # Raw backup data
â”‚
â”œâ”€â”€ logs/                          # Log files (created on first run)
â”‚   â”œâ”€â”€ combined.log               # All logs
â”‚   â””â”€â”€ error.log                  # Error logs only
â”‚
â”œâ”€â”€ package.json                   # Node.js dependencies
â”œâ”€â”€ .env                           # Environment variables (you create this)
â”œâ”€â”€ .env.example                   # Environment template
â”œâ”€â”€ .gitignore                     # Git ignore rules
â”‚
â”œâ”€â”€ README.md                      # Main documentation
â”œâ”€â”€ QUICKSTART.md                  # Quick start guide
â”œâ”€â”€ SETUP_GUIDE.md                 # Detailed setup instructions
â””â”€â”€ PROJECT_STRUCTURE.md           # This file
```

## Key Files Explained

### Core Application

| File | Purpose |
|------|---------|
| `src/index.js` | Main orchestrator - coordinates scraping across platforms |
| `src/cli.js` | Command-line interface for easy usage |
| `src/config/config.js` | Centralized configuration and environment variables |

### Scrapers

| File | Platform | API Used |
|------|----------|----------|
| `src/scrapers/youtube.js` | YouTube | YouTube Data API v3 (Official) |
| `src/scrapers/instagram.js` | Instagram | Puppeteer web scraping |
| `src/scrapers/twitter.js` | Twitter/X | Twitter API v2 (Official) |

### Utilities

| File | Purpose |
|------|---------|
| `src/utils/logger.js` | Logging with Winston (console + file) |
| `src/utils/rateLimiter.js` | Rate limiting to respect API quotas |
| `src/utils/dataOrganizer.js` | Organizes scraped data into structured format |

### Documentation

| File | Content |
|------|---------|
| `README.md` | Overview, features, usage, legal info |
| `QUICKSTART.md` | Get started in 5 minutes |
| `SETUP_GUIDE.md` | Detailed API setup for each platform |
| `PROJECT_STRUCTURE.md` | This file - project organization |
| `examples/training_dataset_format.md` | ML dataset format guide |

## Data Flow

```
1. User Input (CLI or Code)
   â”‚
   â†“
2. PersonaScraper (src/index.js)
   â”‚
   â”œâ”€â†’ YouTubeScraper â†’ YouTube API
   â”œâ”€â†’ InstagramScraper â†’ Puppeteer â†’ Web
   â””â”€â†’ TwitterScraper â†’ Twitter API
   â”‚
   â†“
3. RateLimiter (controls request flow)
   â”‚
   â†“
4. Raw Data Collection
   â”‚
   â†“
5. DataOrganizer
   â”œâ”€â†’ Structured JSON files
   â”œâ”€â†’ Platform-specific folders
   â””â”€â†’ training_dataset.json
   â”‚
   â†“
6. Output (data/persona_name/)
```

## Module Dependencies

```
index.js (PersonaScraper)
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ youtube.js
â”‚   â”‚   â”œâ”€â”€ googleapis
â”‚   â”‚   â”œâ”€â”€ config.js
â”‚   â”‚   â”œâ”€â”€ logger.js
â”‚   â”‚   â””â”€â”€ rateLimiter.js
â”‚   â”‚
â”‚   â”œâ”€â”€ instagram.js
â”‚   â”‚   â”œâ”€â”€ puppeteer
â”‚   â”‚   â”œâ”€â”€ config.js
â”‚   â”‚   â”œâ”€â”€ logger.js
â”‚   â”‚   â””â”€â”€ rateLimiter.js
â”‚   â”‚
â”‚   â””â”€â”€ twitter.js
â”‚       â”œâ”€â”€ twitter-api-v2
â”‚       â”œâ”€â”€ config.js
â”‚       â”œâ”€â”€ logger.js
â”‚       â””â”€â”€ rateLimiter.js
â”‚
â””â”€â”€ utils/
    â”œâ”€â”€ dataOrganizer.js
    â”‚   â”œâ”€â”€ fs/promises
    â”‚   â”œâ”€â”€ config.js
    â”‚   â””â”€â”€ logger.js
    â”‚
    â”œâ”€â”€ logger.js
    â”‚   â””â”€â”€ winston
    â”‚
    â””â”€â”€ rateLimiter.js
        â””â”€â”€ p-queue
```

## NPM Dependencies

### Production Dependencies
- `axios` - HTTP client
- `cheerio` - HTML parsing
- `puppeteer` - Headless browser for web scraping
- `dotenv` - Environment variable management
- `commander` - CLI framework
- `p-queue` - Promise queue for rate limiting
- `winston` - Logging framework
- `googleapis` - YouTube Data API
- `twitter-api-v2` - Twitter API client
- `instagram-private-api` - Instagram API (optional)

### Development Dependencies
- `eslint` - Code linting

## Configuration Files

| File | Purpose |
|------|---------|
| `.env` | Your actual API keys (never commit!) |
| `.env.example` | Template for environment variables |
| `package.json` | NPM package configuration |
| `.gitignore` | Files to exclude from git |

## Output Data Structure

After scraping, each persona gets organized like this:

```
data/persona_name/
â”œâ”€â”€ metadata.json              # Who, when, where
â”œâ”€â”€ summary.json               # Statistics & overview
â”œâ”€â”€ training_dataset.json      # Aggregated ML-ready data
â”‚
â”œâ”€â”€ youtube/
â”‚   â””â”€â”€ youtube_data.json      # Channel, videos, comments
â”‚
â”œâ”€â”€ instagram/
â”‚   â””â”€â”€ instagram_data.json    # Profile, posts
â”‚
â”œâ”€â”€ twitter/
â”‚   â””â”€â”€ twitter_data.json      # User, tweets, likes
â”‚
â””â”€â”€ raw/                       # Backup copies
    â”œâ”€â”€ youtube_raw_data.json
    â”œâ”€â”€ instagram_raw_data.json
    â””â”€â”€ twitter_raw_data.json
```

## Key Features by Component

### YouTube Scraper
- âœ… Channel information & statistics
- âœ… Video metadata (title, description, tags)
- âœ… Video statistics (views, likes, comments)
- âœ… Comment collection (optional)
- âœ… Rate limiting & quota management
- âš ï¸ Transcripts (requires additional setup)

### Instagram Scraper
- âœ… Public profile information
- âœ… Post collection with thumbnails
- âœ… Post details (captions, images)
- âœ… Headless browser scraping
- âš ï¸ Limited by anti-bot measures
- ğŸ’¡ Graph API support (requires setup)

### Twitter Scraper
- âœ… User profile & statistics
- âœ… Tweet collection
- âœ… Tweet metrics (likes, retweets)
- âœ… Liked tweets (optional)
- âœ… Follower list (optional)
- âœ… Content analysis utilities

### Data Organizer
- âœ… Structured directory creation
- âœ… JSON file management
- âœ… Metadata generation
- âœ… Summary statistics
- âœ… ML training dataset export
- âœ… Raw data backup

## Extending the Project

### Adding a New Platform

1. Create `src/scrapers/newplatform.js`
2. Implement the scraper class
3. Add to `src/index.js` in `scrapePlatform()` method
4. Update CLI in `src/cli.js`
5. Add configuration to `src/config/config.js`
6. Update documentation

### Adding New Features

- **Custom analyzers**: Add to `src/utils/`
- **New export formats**: Extend `DataOrganizer`
- **Additional metrics**: Modify scraper classes
- **Pre-processing**: Add to data pipeline

## Best Practices

1. **Always configure `.env`** before running
2. **Start with small limits** to test
3. **Monitor rate limits** in console/logs
4. **Check `logs/` directory** for errors
5. **Backup data** before experiments
6. **Respect ToS** of each platform

## Getting Help

- Check logs: `cat logs/combined.log`
- Read documentation: Start with [QUICKSTART.md](QUICKSTART.md)
- Example code: See [examples/basic_usage.js](examples/basic_usage.js)
- API setup: Follow [SETUP_GUIDE.md](SETUP_GUIDE.md)

---

Last updated: 2024
